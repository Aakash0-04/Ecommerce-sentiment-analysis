{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aba1b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aakash\\AppData\\Local\\Temp\\ipykernel_10524\\3019553400.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d1 = pd.to_datetime(df[\"review_date_raw\"], errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\Aakash\\AppData\\Local\\Temp\\ipykernel_10524\\3019553400.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d1 = pd.to_datetime(df[\"review_date_raw\"], errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\Aakash\\AppData\\Local\\Temp\\ipykernel_10524\\3019553400.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d1 = pd.to_datetime(df[\"review_date_raw\"], errors=\"coerce\", dayfirst=True)\n",
      "C:\\Users\\Aakash\\AppData\\Local\\Temp\\ipykernel_10524\\3019553400.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d1 = pd.to_datetime(df[\"review_date_raw\"], errors=\"coerce\", dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset with 1623 rows.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_and_clean(path, product_name):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Rename Flipkart exported columns\n",
    "    df = df.rename(columns={\n",
    "        \"XQDdHH\": \"rating\",\n",
    "        \"z9E0IG\": \"review_title\",\n",
    "        \"ZmyHeo\": \"review_text\",\n",
    "        \"_2NsDsF\": \"reviewer_name\",\n",
    "        \"MztJPv\": \"verified_purchase\",\n",
    "        \"_2NsDsF 2\": \"review_date\",\n",
    "        \"tl9VpF\": \"helpful_upvotes\",\n",
    "        \"tl9VpF 2\": \"helpful_total\"\n",
    "    })\n",
    "\n",
    "    # Keep only rows with review text\n",
    "    df = df.dropna(subset=[\"review_text\"])\n",
    "\n",
    "    # Convert rating to numeric\n",
    "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "\n",
    "    # Verified buyer flag\n",
    "    df[\"verified_purchase\"] = df[\"verified_purchase\"].astype(str)\n",
    "    df[\"verified_purchase\"] = df[\"verified_purchase\"].apply(\n",
    "        lambda x: True if \"Certified Buyer\" in x else False\n",
    "    )\n",
    "\n",
    "    # Keep raw date text\n",
    "    df[\"review_date_raw\"] = df[\"review_date\"]\n",
    "\n",
    "    # Try to parse dates (but do NOT leave NaT)\n",
    "    d1 = pd.to_datetime(df[\"review_date_raw\"], errors=\"coerce\", dayfirst=True)\n",
    "    d2 = pd.to_datetime(df[\"review_date_raw\"], format=\"%d %b, %Y\", errors=\"coerce\")\n",
    "\n",
    "    # Use whichever parse worked\n",
    "    df[\"review_date\"] = d1.fillna(d2)\n",
    "\n",
    "    # Fill any remaining missing dates with median date\n",
    "    if df[\"review_date\"].isna().sum() > 0:\n",
    "        median_date = df[\"review_date\"].dropna().median()\n",
    "        df[\"review_date\"] = df[\"review_date\"].fillna(median_date)\n",
    "\n",
    "    # Add product name\n",
    "    df[\"product\"] = product_name\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# File Paths\n",
    "# -----------------------------\n",
    "path_s24_pos = r\"C:/Users/Aakash/Desktop/ECOM-- SENTIMENT/Data/Raw/flipkart _samsung_s24.csv\"\n",
    "path_ip15_pos = r\"C:/Users/Aakash/Desktop/ECOM-- SENTIMENT/Data/Raw/flipkart_iphone_15.csv\"\n",
    "path_s24_neg = r\"C:/Users/Aakash/Desktop/ECOM-- SENTIMENT/Data/Raw/flipkart_SamsungS24_negative.csv\"\n",
    "path_ip15_neg = r\"C:/Users/Aakash/Desktop/ECOM-- SENTIMENT/Data/Raw/flipkart_Iphone15_negative.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load All Datasets\n",
    "# -----------------------------\n",
    "df_s24_pos = load_and_clean(path_s24_pos, \"Samsung S24\")\n",
    "df_ip15_pos = load_and_clean(path_ip15_pos, \"iPhone 15\")\n",
    "df_s24_neg = load_and_clean(path_s24_neg, \"Samsung S24\")\n",
    "df_ip15_neg = load_and_clean(path_ip15_neg, \"iPhone 15\")\n",
    "\n",
    "# Combine\n",
    "df_all = pd.concat([df_s24_pos, df_ip15_pos, df_s24_neg, df_ip15_neg], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Save\n",
    "# -----------------------------\n",
    "os.makedirs(\"Data/Processed\", exist_ok=True)\n",
    "df_all.to_csv(\"Data/Processed/flipkart_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Saved cleaned dataset with\", len(df_all), \"rows.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
